# ğŸ§  A Simple Agent Framework with LiteLLM

This project demonstrates a minimal yet functional **AI Agent Loop** using the [LiteLLM](https://github.com/BerriAI/litellm) library, designed to simplify and streamline prompt/response handling with LLMs like OpenAI's GPT-4o.

---

## ğŸš€ Features

- ğŸ§© **Prompt Abstraction**: Easily create prompt objects containing messages, tools, and metadata.
- ğŸ” **Agent Loop Logic**: An extendable loop system that feeds output back into the agent for multi-turn interactions.
- ğŸ” **Secure API Key Handling**: Uses Colabâ€™s `userdata` to keep your API key safe.
- âš™ï¸ **Tool Integration**: Supports tool-calling workflows, extensible via `functions` field.
- ğŸ’¬ **Streamlined Response Handling**: Uses `litellm.completion` to fetch model outputs efficiently.

---

## ğŸ“¦ Dependencies

Make sure you install the required package:

```bash
pip install litellm
```

## ğŸ“ Usage

Open the notebook in **Google Colab**.

Click the ğŸ”‘ icon on the left to set your `OPENAI_API_KEY`.

Use the ğŸ“‚ icon to upload any context files for the agent.

Run the cells to initialize the agent loop and start interacting.

---

## ğŸ§° Core Components

- **Prompt**: A dataclass that wraps `messages`, `tools`, and `metadata`.
- **generate_response(prompt)**: Calls the LLM and returns output.
- **Loop logic**: A basic flow that repeatedly calls the LLM and handles tool-use when needed.

---

## ğŸ§ª Example Use Cases

- Autonomous tool-based question answering  
- Multi-turn task resolution  
- Educational reference for building LLM agents

---

## ğŸ“Œ Notes

This framework is intentionally kept simple for learning and prototyping.

You can easily expand it by defining additional tools and handlers.
